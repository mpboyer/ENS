
\subsection{Résilience statistique}
Le complexe de Vietoris-Rips et ses filtrations se calculent en $\O\left(\abs{\X}^{d}\right)$, ce qui rend le calcul de persistence quasi impossible en pratique.
Par ailleurs, les filtrations et la distance de Gromov-Hausdorff sont très sensibles au bruit et aux anomalies.

\subsubsection{Calcul statistique}
On va s'intéresser à un espace métrique $(\mathbb{M}, \rho)$ et à une mesure de probabilité $\mu$ à support compact $X_{\mu}$ dans $\mathbb{M}$.
On échantillonne $m$ points selon $\mu$, ce qui nous donne un nuage de point $\hatx{m}$, et une filtration
$\filt{\hatx{m}}$.
On a alors:
\begin{proposition}
	Si $\epsilon > 0$:
	\begin{equation*}
		\P\left(\dinf\left(\diag\left(\filt\left(\X_{\mu}\right)\right), \diag\left(\filt\left(\hatx{m}\right)\right)\right) > \epsilon\right) \leq \P\left(d_{GH}\left(\X_{\mu}, \hatx{m}\right) > \frac{\epsilon}{2}\right)
	\end{equation*}
\end{proposition}
\begin{proof}
	Conséquence directe du Théorème \ref{thm:tame-distance-module} de stabilité.
\end{proof}

On obtient quasi immédiatement des inégalités de déviation:
\begin{definition}
	Pour $a, b > 0$, on dit que $\mu$ vérifie \define{la supposition $(a, b)$-standard} si pour $x \in \X_{\mu}$ et $r > 0$, on a:
	\begin{equation*}
		\mu(B(x, r)) \geq \min(ar^{b}, 1)
	\end{equation*}
	On note $\mP(a, b, \mathbb{M})$ \define{l'ensemble des distributions de probabilité $(a, b)$-standard} sur $\M$.
\end{definition}
\begin{thm}
	Si $\mu$ vérifie la supposition $(a, b)$-standard, pour tout $\epsilon > 0$:
	\begin{equation*}
		\P\left(\dinf\left(\diag\left(\filt\left(\X_{\mu}\right)\right), \diag\left(\filt\left(\hatx{m}\right)\right)\right) > \epsilon\right) \leq \min \left(\frac{8^{b}}{a\epsilon^{b}}\exp{\left(-ma\epsilon^{b}\right)}, 1\right)
	\end{equation*}
	De plus:
	\begin{equation*}
		\P\left(\dinf\left(\diag\left(\filt\left(\X_{\mu}\right)\right), \diag\left(\filt\left(\hatx{m}\right)\right)\right) \geq C_{1} \left(\frac{\log{m}}{m}\right)^{1 / b}\right) \xrightarrow[m \to \infty]{} 1
	\end{equation*}
	où $C_{1}$ est une constante qui ne dépend que de $a$ et $b$.
\end{thm}
\begin{proof}
	On commence par majorer $\P\left(\d_{GH}\left(\X_{\mu}, \hatx{m}\right) > \frac{\epsilon}{2}\right)$ puis,
	on obtient par la supposition $(a, b)$-standard une borne supérieure explicite pour la couverture de $\X_{\mu}$ par des boules de rayon $\epsilon / 2$.
	On peut alors conclure en prenant l'union des bornes.
\end{proof}

\begin{thm}
	On a:
	\begin{equation*}
		\sup_{\mu \in \mP(a, b, \mathbb{M})} \E[\dinf(\diag(\filt(\X_{\mu})), \diag(\filt(\hatx{m})))] \leq C(\frac{\ln m}{m})^{1 / b}
	\end{equation*}
	où $C$ ne dépend que de $a$ et $b$.
	Si de plus il y a un point non isolé $x$ dans $\mathbb{M}$, et si $x_{m} \in \mathbb{M} \setminus \{x\}$,
	telle que $\rho(x, x_{m}) \leq (am)^{-1/b}$, pour tout estimateur $\hat{\diag}_{m}$ de $\diag(\filt(\X_{\mu}))$:
	\begin{equation*}
		\liminf_{m \to \infty}\rho(x, x_{m})^{-1}\sup_{\mu \in \mP(a, b, \mathbb{M})}\E[\dinf(\diag(\filt(\X_{\mu})), \hat{\diag}_{m})] \geq C'
	\end{equation*}
	où $C'$ est une constante absolue.
\end{thm}

\subsubsection{Paysages de persistence et rééchantillonnage}
\begin{definition}
	Si on a un diagramme de persistence $(b_{i}, d_{i})$, son \define{paysage de persistence} est obtenu en y ajoutant à chaque point les deux projections orthogonales sur la diagonale par rapport aux axes, puis en plaçant à l'horizontale sa diagonale.
	Formellement, c'est l'union pour $p = (\frac{b + d}{2}, \frac{d - b}{2})$ des graphes:
	\begin{equation*}
		\Lambda_{p}(t) = \begin{cases}
			t - b & t \in [b, \frac{b + d}{2}] \\
			d - t & t \in [\frac{b + d}{2}, d] \\
			0     & \text{sinon}
		\end{cases}
	\end{equation*}
\end{definition}

C'est un encodage de la persistence comme un élément d'un espace fonctionnel, comme fait ci-dessous:
\begin{definition}
	On définit le \define{$k$-ème paysage} d'un diagramme $D$ par:
	\begin{equation*}
		\lambda_{D}(k, t) = \underset{p \in D}{\mathrm{kmax}} \Lambda_{p}(t), t \in \R, k \in \N
	\end{equation*}
	où $\mathrm{kmax}$ désigne le $k$-ème plus grand élément d'un ensemble.
\end{definition}

\begin{proposition}\label{thm:landscape-stability}
	\begin{itemize}
		\item Pour $t \in \R$ et $k \in \N$, $0 \leq \lambda_{D}(k, t) \leq \lambda_{D}(k + 1, t)$
		\item Pour $t \in \R$, et $k \in \N$, $\abs{\lambda_{D}(k, t) - \lambda_{D'}(k, t)} \leq \dinf(D, D')$
	\end{itemize}
\end{proposition}

Dans la suite, on note $\mL_{T}$ les paysages dont le support est dans $[0, T]$, on prend $P$ une distribution de probabilité
sur $\mL_{T}$ et $\lambda_{1}, \ldots, \lambda_{n} \sim P$ i.i.d.
On note $\mu(t) = \E[\lambda_{i}(t)]$ le paysage moyen et on l'estime par la moyenne échantillonnée:
\begin{equation*}
	\bar{\lambda}_{n}(t) = \frac{1}{n}\sum \lambda_{i}(t)
\end{equation*}
$\bar{\lambda}_{n}$ est un estimateur point à point non biaisé de $\mu$, qui converge point à point.

\begin{definition}
	Soit $\mF$ la famille des applications d'évaluation $f_{t} : \mL_{T} \to \R$.
	Le \define{processus empirique} indexé par les $f_{t}$ est défini par:
	\begin{equation*}
		\mathbb{G}_{n}(t) = \sqrt{n}(\bar{\lambda}_{n}(t) - \mu_{t}) = \sqrt{n}(P_{n} - P)(f_{t})
	\end{equation*}
\end{definition}

\begin{thm}
	Soit $\mathbb{G}$ un pont Brownien avec fonction de covariance:
	\begin{equation*}
		\kappa(s, t) = \int f_{t}(\lambda)f_{s}(\lambda)\d P(\lambda) - \int f_{t}(\lambda)\d P(\lambda)\int f_{s}(\lambda)\d P(\lambda).
	\end{equation*}
	On a alors:
	\begin{equation*}
		\mathbb{G}_{n} \to \mathbb{G}
	\end{equation*}
	pour la convergence faible.
\end{thm}

Si de plus on note $\sigma(t)$ l'écart-type de $\sqrt{n}\bar{\lambda}_{n}(t)$:
\begin{thm}\label{thm:bootstrap-clt}
	Si $\sigma(t) > c > 0$ sur un intervalle $I = [t_{*}, t^{*}] \subseteq [0, T]$ pour une constance $c$, avec
	$W = \sup_{t \in I} \abs{\mathbb{G}(f_{t})}$ on a:
	\begin{equation*}
		\sup_{z \in \R}\abs{\P\left(\sup_{t \in [t_{*}, t^{*}]}\abs{\mathbb{G}_{n}\left(t\right)} \leq z\right) - \P\left(W \leq z\right)} = \O\left(\frac{\left(\log n\right)^{7 / 8}}{n^{1 / 8}}\right)
	\end{equation*}
\end{thm}
C'est une forme de théorème central limite uniforme. On a de plus le corollaire suivant:

\begin{thm}
	Sous les mêmes hypothèses, étant donné un niveau de confiance $1 - \alpha$, on peut construire des fonctions de confiance
	$l_{n}(t)$ et $u_{n}(t)$ telles que:
	\begin{equation*}
		\P\left(l_{n}(t) \leq \mu(t) \leq u_{n}(t), \forall t \in I\right) \geq 1 - \alpha - \O\left(\frac{\left(\log n\right)^{7/8}}{n^{1 / 8}}\right)
	\end{equation*}
	De plus, on a:
	\begin{equation*}
		\sup_{t} u_{n}(t) - l_{n}(t) = \O\left(\sqrt{\frac{1}{n}}\right)
	\end{equation*}
\end{thm}
Autrement dit, le rééchantillonnage (ou \textit{bootstrap}) permet d'obtenir des intervalles de confiance pour les paysages.

\subsubsection{Bruit et méthode d'échantillonnage}
On va ici s'intéresser à l'impact de la procédure d'échantillonnage.
On rappelle que la définition des distances de $p$-Wasserstein peuvent se poser pour n'importe quelles
deux mesures de probabilité sur un même espace métrique $(\mathbb{M}, \rho)$.
On a notamment le théorème suivant:
\begin{thm}\label{thm:sampling-stability}
	Si $\mu, \nu$ sont des mesures de probabilité sur un même espace métrique $(\mathbb{M}, \rho)$, on a:
	\begin{equation*}
		\ninf{\Lambda_{\mu, m} - \Lambda_{\nu, m}} \leq m^{\frac{1}{p}} \mathrm{W}_{p}\left(\mu, \nu\right)
	\end{equation*}
	où $\mathrm{W}_{p}$ dénote la distance de Wasserstein associée à la fonction de coût $\rho(\cdot, \cdot)^{p}$.
\end{thm}
Ceci nous assure de l'utilisabilité des méthodes d'échantillonnage, et notamment de la robustesse
aux échantillons peu probables et des méthodes sous-échantillonnant.

Avant de démontrer ceci, donnons trois courts lemmes sur les passages des espaces d'échantillonnage aux espaces de paysages:
\begin{lemme}\label{lem:samp-one}
	Pour toutes mesures de probabilité $\mu, \nu$ sur $(\mathbb{M}, \rho)$, si $\rho_{m}$ est une métrique sur $\mathbb{M}^{m}$ telle que:
	\begin{equation*}
		\rho_{m}(X, Y) \leq \left(\sum_{i = 1}^{m}\rho(x_{i}, y_{i})^{p}\right)^{\frac{1}{p}}
	\end{equation*}
	alors:
	\begin{equation*}
		\W_{p}(\mu^{\otimes m}, \nu^{\otimes m}) \leq m^{\frac{1}{p}}\W_{p}(\mu, \nu)
	\end{equation*}
\end{lemme}
\begin{proof}
	Si $\Pi$ est un plan de transport entre $\mu$ et $\nu$, alors $\Pi^{\otimes m}$ est un plan de transport entre $\mu^{\otimes m}$ et $\nu^{\otimes m}$ et donc:
	\begin{align*}
		\int_{\MM^{2m}}\rho_{m}(X, Y)^{p}\d\Pi^{\otimes m}(X, Y) \leq & \int_{\MM^{m}\times \MM^{m}}\sum_{i = 1}^{m}\rho(x_{i}, y_{i})^{p}\d\Pi(x_{1}, y_{1})\cdots\d\Pi(x_{m}, y_{m}) \\
		= m\int_{\MM \times \MM}\rho(x_{1}, y_{1})^{p}\d \Pi(x_{1}, y_{1}),
	\end{align*}
	ce qui conclut la preuve.
\end{proof}

\begin{lemme}\label{lem:samp-two}
	En notant $\phi^{m}: \MM^{m} \to \mD$ la fonction qui à $X$ associe $\diag\left(\filt X\right)$ dans l'espace des diagrammes de persistence et si $\Phi_{\mu}^{m}$ est le poussé en avant de $\mu$ par $\phi^{m}$:
	\begin{equation*}
		\W_{p}(\Phi_{\mu}^{m}, \Phi_{\nu}^{m}) \leq \W_{p}(\mu^{\otimes m}, \nu^{\otimes m})
	\end{equation*}
\end{lemme}
\begin{proof}
	En notant $\Delta_{m}(X, Y) = (\psi(\phi^{m}(X)), \psi(\phi^{m}(Y)))$, si $\Pi$ est un plan entre $\mu^{\otimes m}$ et $\nu^{\otimes m}$, alors le plan $\Delta_{m}\sharp \Pi$ poussé en avant de $\Pi$ est un plan entre $\Phi_{\mu}^{m}$ et $\Phi_{\nu}^{m}$ et on a:
	\begin{align*}
		\int_{\mD^{2}} \W_{\infty}(D_{X}, D_{Y})^{p}\d \Delta_{m}\sharp\Pi(D_{X}, D_{Y}) = & \int_{\MM^{2m}}\W_{\infty}(\phi^{m}(X), \phi^{m}(Y))^{p}\d\Pi(X, Y)                        \\
		\leq                                                                               & \int_{\MM^{2m}} d_{H}(X, Y)^{p}\d\Pi(X, Y) \quad \text{(\ref{thm:tame-distance-function})} \\
		\leq                                                                               & \int_{\MM^{2m}}\rho_{m}(X, Y)^{p}\d\Pi(X, Y)
	\end{align*}
\end{proof}


\begin{lemme}\label{lem:samp-three}
	En notant $\psi$ l'application de l'espace des diagrammes vers l'espace des paysages munis de la norme infinie et $\Psi_{\mu}^{m}$ le poussé en avant de $\phi_{\mu}^{m}$ par $\psi$:
	\begin{equation*}
		\ninf{\E_{\lambda_{X} \sim \Psi_{\mu}^{m}}[\lambda_{X}] - \E_{\lambda_{Y} \sim \Psi_{\nu}^{m}}\left[\lambda_{Y}\right]} \leq \W_{\infty, p}(\Phi_{\mu}^{m}, \Phi_{\nu}^{m})
	\end{equation*}
	où $\W_{\infty, p}$ fait appel à la $p$-ème puissance de la distance infinie de Wasserstein pour les diagrammes sous-jacents.
\end{lemme}
\begin{proof}
	Si $\Pi$ est un plan entre $\Phi_{\mu}^{m}$ et $\Phi_{\nu}^{m}$, pour tout $t \in \R$ on a:
	\begin{align*}
		\abs{\E_{\lambda_{X} \sim \Psi_{\mu}^{m}}\left[\lambda_{X}\right]\left(t\right) - \E_{\lambda_{Y} \sim \Psi_{\nu}^{m}}\left[\lambda_{Y}\right]\left(t\right)}^{p} = & \abs{\E\left[\lambda_{X}(t) - \lambda_{Y}(t)\right]}^{p}                                             \\
		\leq                                                                                                                                                                & \E\left[\abs{\lambda_{X}(t) - \lambda_{Y}(t)}^{p}\right] \quad \text{(Jensen)}                       \\
		\leq                                                                                                                                                                & \E\left[\W_{\infty}\left(D_{X}, D_{Y}\right)^{p}\right] \quad \text{(\ref{thm:landscape-stability})} \\
		=                                                                                                                                                                   & \int_{\mD \times \mD}\W_{\infty}(D_{X}, D_{Y})^{p}\d\Pi(D_{X}, D_{Y})
	\end{align*}
\end{proof}

\begin{proof}[Preuve du Théorème \ref{thm:sampling-stability}]
	Par le Lemme \ref{lem:samp-one} ci-dessus
	\begin{equation*}
		\W_{p}\left(\mu^{\otimes m}, \nu^{\otimes m}\right) \leq m^{\frac{1}{p}}\W_{p}(\mu, \nu)
	\end{equation*}
	Par le Lemme \ref{lem:samp-two}, en notant $P_{\pi}$ le diagramme de persistence associé à $\pi$:
	\begin{equation*}
		\W_{p}(P_{\mu}, P_{\nu}) \leq \W_{p}(\mu^{\otimes m}, \nu^{\otimes m})
	\end{equation*}
	Enfin, par le Lemme \ref{lem:samp-three}:
	\begin{equation*}
		\ninf{\Lambda_{\mu, m} - \Lambda_{\nu, m}} \leq \W_{p}(P_{\mu}, P_{\nu})
	\end{equation*}
\end{proof}


